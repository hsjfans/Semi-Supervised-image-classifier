{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fix_match import FixMatch\n",
    "import torch\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from data_loader import load_data\n",
    "import torch.optim as optim\n",
    "from config import train_path, test_path, val_path, unlabel_path, lambda_u, num_class,\\\n",
    "    mu, batch_size, lr, beta, weight_decay, epochs, threshold\n",
    "from tqdm import tqdm\n",
    "from config import device\n",
    "#  train_loader, test_dataset, val_loader, unlabel_loader\n",
    "\n",
    "\n",
    "def run_batch(label_img, label, weak_img, strong_img, model, lambda_u, threshold):\n",
    "    weak_img.to(device), strong_img.to(\n",
    "        device), label_img.to(device), label.to(device)\n",
    "    out, a_u, A_u = model(label_img, weak_img, strong_img)\n",
    "    acc = (torch.argmax(out, dim = 1) == label).sum().item() / len(label)\n",
    "    # 1) Cross-entropy loss for labeled data.\n",
    "    l_x = F.nll_loss(out, label)\n",
    "\n",
    "    # 2) Cross-entropy loss with pseudo-label B and conﬁdence for unlabeled data\n",
    "    max_probs, a_u_label = torch.max(a_u, dim=1)\n",
    "    mask = max_probs.ge(threshold).float()\n",
    "    l_u = (F.nll_loss(A_u,a_u_label.detach(),reduction='none') * mask).mean()\n",
    "    loss = l_x + lambda_u * l_u\n",
    " \n",
    "    return loss, acc\n",
    "\n",
    "\n",
    "def run_val_epoch(model, val_loader, batch_size):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    acc = 0.0\n",
    "    for img, label in val_loader:\n",
    "        img.to(device), label.to(device)\n",
    "        out = model.predict(img)\n",
    "        acc += (torch.argmax(out, dim=1) == label).sum().item() / batch_size\n",
    "        L = F.cross_entropy(out, label)\n",
    "        loss += L.item()\n",
    "    return loss / len(val_loader), acc / len(val_loader)\n",
    "\n",
    "\n",
    "def run_train_epoch(model, op, train_loader, unlabel_loader, max_batch, lambda_u, threshold):\n",
    "    model.train()\n",
    "    loss = 0.0\n",
    "    total_acc = 0.0\n",
    "    labeled_iter = iter(train_loader)\n",
    "    unlabeled_iter = iter(unlabel_loader)\n",
    "\n",
    "    for _ in range(max_batch):\n",
    "        try:\n",
    "            img, label = labeled_iter.next()\n",
    "        except:\n",
    "            labeled_iter = iter(train_loader)\n",
    "            img, label = labeled_iter.next()\n",
    "\n",
    "        try:\n",
    "            weak_img, strong_img = unlabeled_iter.next()\n",
    "        except:\n",
    "            unlabeled_iter = iter(unlabel_loader)\n",
    "            weak_img, strong_img = unlabeled_iter.next()\n",
    "\n",
    "        L, acc = run_batch(img, label, weak_img, strong_img,\n",
    "                           model, lambda_u, threshold)\n",
    "        total_acc += acc\n",
    "        loss += L.item()\n",
    "        L.backward()\n",
    "        op.step()\n",
    "\n",
    "    return loss / max_batch, total_acc / max_batch\n",
    "\n",
    "\n",
    "def save_model(model, epoch):\n",
    "    check_point = {'model': model.state_dict(), 'epoch': epoch}\n",
    "    torch.save(check_point, f'epoch_{epoch}.pt')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FixMatch(num_class, 34)\n",
    "model.to(device)\n",
    "op = optim.SGD(model.parameters(), lr=lr,\n",
    "                   weight_decay=weight_decay, momentum=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "200it [00:08, 24.27it/s]\n",
      "100%|██████████| 10000/10000 [00:07<00:00, 1329.06it/s]\n",
      "100%|██████████| 10000/10000 [00:08<00:00, 1169.02it/s]\n",
      "100%|██████████| 90000/90000 [01:32<00:00, 975.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader, unlabel_loader, labels = load_data(\n",
    "        train_path, val_path, test_path, unlabel_path, batch_size, mu)\n",
    "max_batch = int(max(len(train_loader) / batch_size,\n",
    "                        len(unlabel_loader) / batch_size / mu))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "iter(unlabel_loader).next()[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/10 [00:35<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "split_with_sizes expects split_sizes to sum exactly to 160 (input tensor's size at dimension 0), but got split_sizes=[32, 32, 32]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ac1cda2c0ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     train_loss, train_acc = run_train_epoch(model, op, train_loader, unlabel_loader,\n\u001b[0;32m----> 8\u001b[0;31m                                                 max_batch, lambda_u, threshold)\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_val_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-596f48295936>\u001b[0m in \u001b[0;36mrun_train_epoch\u001b[0;34m(model, op, train_loader, unlabel_loader, max_batch, lambda_u, threshold)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         L, acc = run_batch(img, label, weak_img, strong_img,\n\u001b[0;32m---> 65\u001b[0;31m                            model, lambda_u, threshold)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mtotal_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-596f48295936>\u001b[0m in \u001b[0;36mrun_batch\u001b[0;34m(label_img, label, weak_img, strong_img, model, lambda_u, threshold)\u001b[0m\n\u001b[1;32m     15\u001b[0m     weak_img.to(device), strong_img.to(\n\u001b[1;32m     16\u001b[0m         device), label_img.to(device), label.to(device)\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrong_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# 1) Cross-entropy loss for labeled data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/docs/projects/FixMatch/fix_match/fix_match.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, label_img, weak_img, strong_img)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabel_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_u\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrong_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrong_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/docs/projects/FixMatch/fix_match/fix_match.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, label_img, weak_img, strong_img)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maug_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         label_out, a_u, A_u = torch.split(\n\u001b[0m\u001b[1;32m     22\u001b[0m             out, [label_size, aug_size, aug_size], dim=0)\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabel_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_u\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(tensor, split_size_or_sections, dim)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# split_size_or_sections. The branching code is in tensor.py, which we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# call here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# equivalent to itertools.product(indices)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/ml/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, split_size, dim)\u001b[0m\n\u001b[1;32m    377\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_with_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: split_with_sizes expects split_sizes to sum exactly to 160 (input tensor's size at dimension 0), but got split_sizes=[32, 32, 32]"
     ]
    }
   ],
   "source": [
    "val_loss_list = []\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "train_acc_list = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    start = time.time()\n",
    "    train_loss, train_acc = run_train_epoch(model, op, train_loader, unlabel_loader,\n",
    "                                                max_batch, lambda_u, threshold)\n",
    "    val_loss, val_acc = run_val_epoch(model, val_loader, batch_size)\n",
    "    train_loss_list.append(train_loss)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_acc_list.append(val_acc)\n",
    "    train_acc_list.append(train_acc)\n",
    "    interval = time.time() - start\n",
    "    print(f'[Epoch]:{epoch}/{epochs}, train_loss:{train_loss}, train_acc: {train_acc}, val_loss:{val_loss}, val_acc:{val_acc}, time:{interval}s')\n",
    "    if epoch % 5 == 0:\n",
    "        save_model(model, epoch)\n",
    "save_model(model, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}